# Proiect Limbaje Formale - Text Summarization cu BART

**Universitatea TehnicÄƒ din Cluj-Napoca**  
**Abstractive Summarization folosind facebook/bart-large-cnn**

---

## ğŸ“‹ Descriere

Acest proiect demonstreazÄƒ **Abstractive Text Summarization** folosind modelul BART (Bidirectional and Auto-Regressive Transformers) de la Facebook/Meta, pre-antrenat pe dataset-ul CNN/DailyMail.

Spre deosebire de **extractive summarization** (care extrage propoziÈ›ii existente), **abstractive summarization** genereazÄƒ text nou, parafrazÄƒ È™i condenseazÄƒ informaÈ›ia ca un om.

---

## ğŸ¯ FuncÈ›ionalitÄƒÈ›i

âœ… **InterfaÈ›Äƒ web interactivÄƒ** (Gradio) - foarte uÈ™or de folosit!  
âœ… Summarization pe texte Ã®n limba englezÄƒ  
âœ… Control asupra lungimii rezumatului (scurt/mediu/lung)  
âœ… 3 texte de exemplu pre-Ã®ncÄƒrcate (click È™i se Ã®ncarcÄƒ)  
âœ… Statistici de compresie Ã®n timp real  
âœ… Input text custom - introdu propriul tÄƒu text  
âœ… Script pentru terminal (varianta alternativÄƒ)  
âœ… Comentarii detaliate Ã®n romÃ¢nÄƒ Ã®n cod  

---

## ğŸ› ï¸ Tehnologii folosite

- **Python 3.8+**
- **HuggingFace Transformers** - biblioteca pentru modele NLP
- **PyTorch** - framework de deep learning
- **BART** (`facebook/bart-large-cnn`) - modelul de summarization

---

## ğŸ“¦ Instalare

### 1. CloneazÄƒ/DescarcÄƒ proiectul

```bash
cd c:\Users\Abraham\Desktop\proiect_limbaje
```

### 2. ConfigureazÄƒ mediul virtual (RECOMANDAT)

**OpÈ›iunea A - AutomatÄƒ (Windows):**
```cmd
setup_venv.bat
```

**OpÈ›iunea B - ManualÄƒ:**
```bash
# CreeazÄƒ mediul virtual
python -m venv venv

# ActiveazÄƒ-l
venv\Scripts\activate

# Upgrade pip
python -m pip install --upgrade pip

# InstaleazÄƒ dependinÈ›ele
pip install -r requirements.txt
```

---

## ğŸš€ Utilizare

### **OpÈ›iunea A - InterfaÈ›Äƒ Web (RECOMANDAT)** ğŸŒ

**Pornire rapidÄƒ:**
```cmd
run_app.bat
```

**Sau manual:**
```bash
venv\Scripts\activate
python app.py
```

AplicaÈ›ia va porni Ã®n browser la: **http://127.0.0.1:7860**

---

### **OpÈ›iunea B - Script Ã®n Terminal** ğŸ’»

```bash
venv\Scripts\activate
python summarization_bart.py
```

---

## ğŸ“‚ Structura proiectului

```
proiapp.py                     # ğŸŒ AplicaÈ›ie web cu interfaÈ›Äƒ Gradio (RECOMANDAT)
â”œâ”€â”€ summarization_bart.py      # ğŸ’» Script pentru terminal (alternativÄƒ)
â”œâ”€â”€ requirements.txt            # DependinÈ›e Python
â”œâ”€â”€ setup_venv.bat             # Setup automat pentru Windows
â”œâ”€â”€ run_app.bat                # Pornire rapidÄƒ aplicaÈ›ie web
â”œâ”€â”€ requirements.txt            # DependinÈ›e Python
â”œâ”€â”€ setup_venv.bat             # Setup automat pentru Windows
â”œâ”€â”€ README.md                  # DocumentaÈ›ie (acest fiÈ™ier)
â”‚
â””â”€â”€ venv/                      # Mediu virtual (se creeazÄƒ la instalare)
```

---

## ğŸ§ª Exemple de output

**Text original (150 cuvinte):**
```
Artificial intelligence is transforming the technology industry...
[text complet]
```

**Rezumat generat (35 cuvinte):**
```
AI is transforming tech industry. Major companies invest billions in research. 
Machine learning can now perform tasks requiring human intelligence. 
Experts predict AI will revolutionize healthcare, finance, and education.
```

**Compresie:** ~77%

---

## ğŸ“ Concepte teoretice

### Extractive vs Abstractive Summarization

| Extractive | Abstractive |
|------------|-------------|
| Extrage propoziÈ›ii din text | GenereazÄƒ text nou |
| Mai simplu | Mai complex |
| Poate pÄƒrea tÄƒiat | Mai natural, coerent |
| Exemplu: TF-IDF, TextRank | Exemplu: BART, T5, Pegasus |

### Modelul BART

BART = **B**idirectional and **A**uto-**R**egressive **T**ransformers

- **Encoder-Decoder** architecture
- Pre-antrenat pe CNN/DailyMail (news summarization)
- CombinÄƒ avantajele BERT (encoder) È™i GPT (decoder)
- Excelent pentru:
  - Text summarization
  - Translation
  - Text generation

---

## âš™ï¸ Configurare lungime rezumat

Ãn cod poÈ›i ajusta lungimea rezumatului modificÃ¢nd parametrii:

```python
configurari_lungime = {
    "scurt": {"min_length": 30, "max_length": 60},
    "mediu": {"min_length": 60, "max_length": 130},
    "lung": {"min_length": 100, "max_length": 200}
}
```

---

## ğŸ› Troubleshooting

**Eroare: "Python nu este instalat"**
- DescarcÄƒ Python de la: https://www.python.org/downloads/
- AsigurÄƒ-te cÄƒ este adÄƒugat Ã®n PATH

**Eroare: "No module named 'transformers'"**
- ActiveazÄƒ mediul virtual: `venv\Scripts\activate`
- ReinstaleazÄƒ: `pip install -r requirements.txt`

**Procesul dureazÄƒ mult la prima rulare**
- Normal! Modelul se descarcÄƒ (â‰ˆ1.6 GB) la prima utilizare
- Se salveazÄƒ Ã®n cache, urmÄƒtoarele rulÄƒri sunt rapide

**RAM insuficient**
- Modelul BART necesitÄƒ ~4-6 GB RAM
- Ãnchide alte aplicaÈ›ii
- AlternativÄƒ: foloseÈ™te `facebook/bart-base` (mai mic)

---

## ğŸ“š Resurse utile

- [HuggingFace Transformers Docs](https://huggingface.co/docs/transformers)
- [BART Paper](https://arxiv.org/abs/1910.13461)
- [facebook/bart-large-cnn Model](https://huggingface.co/facebook/bart-large-cnn)

---

## ğŸ‘¥ Autori

**Proiect realizat pentru:** Limbaje Formale - UTCN  
**EchipÄƒ:** 2 persoane  

---

## ğŸ“ LicenÈ›Äƒ

Acest proiect este realizat Ã®n scop educaÈ›ional pentru UTCN.

---

## ğŸ”œ Extensii posibile

- [ ] Suport pentru limba romÃ¢nÄƒ (model multilingv)
- [ ] InterfaÈ›Äƒ web (Gradio/Streamlit)
- [ ] Deploy pe HuggingFace Spaces
- [ ] ComparaÈ›ie cu alte modele (T5, Pegasus)
- [ ] Fine-tuning pe dataset custom
- [ ] API REST pentru integrare

---

**Ãšltima actualizare:** Ianuarie 2026
